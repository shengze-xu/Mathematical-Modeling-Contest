{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f939e13e-e09e-473a-b03a-53ae0e1678f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import testCases \n",
    "from dnn_utils import sigmoid, sigmoid_backward, relu, relu_backward \n",
    "import lr_utils \n",
    "\n",
    "np.random.seed(1)\n",
    "def initialize_parameters(n_x,n_h,n_y):\n",
    "    \n",
    "#     此函数是为了初始化两层网络参数而使用的函数。\n",
    "#     参数：\n",
    "#         n_x - 输入层节点数量\n",
    "#         n_h - 隐藏层节点数量\n",
    "#         n_y - 输出层节点数量\n",
    "    \n",
    "#     返回：\n",
    "#         parameters - 包含你的参数的python字典：\n",
    "#             W1 - 权重矩阵,维度为（n_h，n_x）\n",
    "#             b1 - 偏向量，维度为（n_h，1）\n",
    "#             W2 - 权重矩阵，维度为（n_y，n_h）\n",
    "#             b2 - 偏向量，维度为（n_y，1）\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    #使用断言确保我的数据格式是正确的\n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fb7c716-05ca-4089-a8b8-127e91a2ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============测试initialize_parameters==============\n",
      "W1 = [[ 0.01624345 -0.00611756 -0.00528172]\n",
      " [-0.01072969  0.00865408 -0.02301539]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[ 0.01744812 -0.00761207]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"==============测试initialize_parameters==============\")\n",
    "parameters = initialize_parameters(3,2,1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f62aeac5-84b3-49cb-9750-fc4692a45a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============测试linear_forward==============\n",
      "Z = [[ 3.26295337 -1.23429987]]\n"
     ]
    }
   ],
   "source": [
    "def linear_forward(A,W,b):\n",
    "#     \"\"\"\n",
    "#     实现前向传播的线性部分。\n",
    "\n",
    "#     参数：\n",
    "#         A - 来自上一层（或输入数据）的激活，维度为(上一层的节点数量，示例的数量）\n",
    "#         W - 权重矩阵，numpy数组，维度为（当前图层的节点数量，前一图层的节点数量）\n",
    "#         b - 偏向量，numpy向量，维度为（当前图层节点数量，1）\n",
    "\n",
    "#     返回：\n",
    "#          Z - 激活功能的输入，也称为预激活参数\n",
    "#          cache - 一个包含“A”，“W”和“b”的字典，存储这些变量以有效地计算后向传递\n",
    "#     \"\"\"\n",
    "    Z = np.dot(W,A) + b\n",
    "    assert(Z.shape == (W.shape[0],A.shape[1]))\n",
    "    cache = (A,W,b)\n",
    "    return Z,cache\n",
    "print(\"==============测试linear_forward==============\")\n",
    "A,W,b = testCases.linear_forward_test_case()\n",
    "Z,linear_cache = linear_forward(A,W,b)\n",
    "print(\"Z = \" + str(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85c8d3ec-baa9-4a56-afcc-8d231a60a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============测试linear_activation_forward==============\n",
      "sigmoid，A = [[0.96890023 0.11013289]]\n",
      "ReLU，A = [[3.43896131 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def linear_activation_forward(A_prev,W,b,activation):\n",
    "#     \"\"\"\n",
    "#     实现LINEAR-> ACTIVATION 这一层的前向传播\n",
    "\n",
    "#     参数：\n",
    "#         A_prev - 来自上一层（或输入层）的激活，维度为(上一层的节点数量，示例数）\n",
    "#         W - 权重矩阵，numpy数组，维度为（当前层的节点数量，前一层的大小）\n",
    "#         b - 偏向量，numpy阵列，维度为（当前层的节点数量，1）\n",
    "#         activation - 选择在此层中使用的激活函数名，字符串类型，【\"sigmoid\" | \"relu\"】\n",
    "\n",
    "#     返回：\n",
    "#         A - 激活函数的输出，也称为激活后的值\n",
    "#         cache - 一个包含“linear_cache”和“activation_cache”的字典，我们需要存储它以有效地计算后向传递\n",
    "#     \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert(A.shape == (W.shape[0],A_prev.shape[1]))\n",
    "    cache = (linear_cache,activation_cache)\n",
    "    \n",
    "    return A,cache\n",
    "print(\"==============测试linear_activation_forward==============\")\n",
    "A_prev, W,b = testCases.linear_activation_forward_test_case()\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"sigmoid\")\n",
    "print(\"sigmoid，A = \" + str(A))\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"relu\")\n",
    "print(\"ReLU，A = \" + str(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007243b-5282-4a19-b361-702cfc83a2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
